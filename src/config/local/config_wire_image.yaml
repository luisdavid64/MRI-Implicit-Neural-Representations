# Logger options
log_iter: 50                # How often to log the training loss 
val_epoch: 3               # How often to validate testing and save output images during training
image_save_epoch: 5        # How often do you want to save output images during training
display_image_num: 8

# Optimization options
max_epoch: 500                # Maximum number of training iterations
batch_size: 10000               # Batch size (320x320)
loss: L2
optimizer: Adam               # Optimizer for trainings
weight_decay: 0.000000001             # Weight decay
beta1: 0.9                    # Adam parameter
beta2: 0.999                  # Adam parameter
lr: 0.005                    # Initial learning rate
 # WIRE works best at 5e-3 to 2e-2, Gauss and SIREN at 1e-3 - 2e-3,

# Regularization
# Supported L1 (Lasso), L2 (Ridge) or none
regularization:
  type: none # L1, L2 or None
  strenght : 0.001 # lambda value

################## 3D CT Image ###################
# Model options (3D CT)

model: WIRE                   # Options for MLP models [FFN | SIREN]
net: 
  network_input_size: 3     # Input size for network
  network_output_size: 2 
  network_depth: 4            # Depth of MLP layers
  network_width: 256          # Width of MLP layers
  first_omega_0: 30
  hidden_omega_0: 30
  scale: 15

encoder:
  embedding: none            #  Input embedding method
  scale: 4
  embedding_size: 256         # Embedding size for input Fourier feature encoding
  coordinates_size: 3


# Data
data: brain # or knee
data_root: data
set: train
slice: 0
sample: 0
transform: True      # Set to false for k-space
full_norm: True
all_slices: False
slices:
  - 0
  - 2
  - 4

# Undersamping paramters
# Supported formats:
#   grid-x*y          example: grid-3*3
#   random_line-p     example: random_line-0.5   (note: p should be in [0,1] range)
#   none              So no undersamping
undersampling: uniform_random-0.5